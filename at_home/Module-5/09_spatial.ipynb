{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Week\n",
    "\n",
    "* Spatial data manipulation (GeoPandas, Shapely)\n",
    "* Spatial data analysis (PySAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title of this course is \"GIS Programming: Principles of Programming for GIScientists.\" We have spent most of our time so far focused on the \"principles of programming\" aspect of the course.  The goal has been to provide you with a solid background in programming for data analysis so that you can use __any__ python library, not just those in the GIS sphere.\n",
    "\n",
    "This week we (finally) introduce some packages specifically targeted for spatial data. These will be supplemented in the coming weeks when you all present on other specialized packages in your projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation \n",
    "\n",
    "One of the strengths of Anaconda Python is the ability to create \"environments.\" These are encapsulated python installations that can live side-by-side on your hard drive. This is useful because what you install in one environment does not affect other environments. If one package conflicts with another, you can keep them in their own environments. So far in the semester we have been using the `default` (or `base`) environment. \n",
    "\n",
    "Open source spatial packages are notoriously difficult to install. Therefore, we will create a new environment called `gis2019` that has the basic spatial tools you need to know. \n",
    "\n",
    "Open up a new Anaconda Prompt (Windows) or Terminal (Mac) and type the following (press `Enter` after each line): \n",
    "```\n",
    "conda create --name gis2019 -c conda-forge python=3 geopandas jupyter seaborn palettable spyder ipykernel\n",
    "conda activate gis2019\n",
    "ipython kernel install --user\n",
    "```\n",
    ">If you are running this in Windows, enter the line below.\n",
    ">```\n",
    "conda install pywin32\n",
    ">```\n",
    "\n",
    "Running the above lines will take awhile to install. **Notice we are installing Python3 in this environment.** Anaconda is flexible in this way. GeoPandas and its dependencies are not compatible with Python2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After installing the environment\n",
    "\n",
    "* Once it is done, close and re-open Jupyter Notebook and return to this notebook. \n",
    "* Then click `Kernel` > `Change kernel` > `Python 3`\n",
    "* Assuming all went well, you should be ready to go with geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "gpd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "shapely.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__STOP__: If you don't have geopandas version 0.6.1 and shapely version at least 1.6.4.post1, post to the [associated Canvas discussion](https://canvas.fsu.edu/courses/102434/discussion_topics/589658) what you do have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">GeoPandas is an open source project to make working with geospatial data in python easier. GeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types. Geometric operations are performed by shapely. Geopandas further depends on fiona for file access and descartes and matplotlib for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What GeoPandas does...\n",
    "\n",
    "* Geometry operations (Shapely)\n",
    "* Data alignment (pandas)\n",
    "* Coordinate transformations (pyproj)\n",
    "* Read/write GIS file formats (Fiona)\n",
    "    * Shapefiles\n",
    "    * PostGIS\n",
    "    * geoJSON\n",
    "* Plotting (matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoPandas has many dependencies. You already have pandas and matplotlib installed, and now you will get:\n",
    "\n",
    "* Shapely \n",
    "* Fiona\n",
    "* Pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation on geopandas is thin relative to other packages you've seen this semester. However, geopandas is tightly coupled with its dependencies, so it is often the case that help resources are better found in the documentation for [shapely](http://toblerity.org/shapely/) or [pandas](http://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas is built around the **GeoDataFrame**. The key difference between the pandas (DataFrame) and geopandas (GeoDataFrame) versions is the **`geometry` column**, which contains the spatial information on the observation. If you had a DataFrame with columns `tree_height` and `tree_diameter`, a GeoDataFrame would have three columns: `tree_height`, `tree_diameter` and `geometry`. In this case the `geometry` column would hold the geographic coordinates of the tree locations. The `geometry` column can hold point, line or polygon coordinates.\n",
    "\n",
    "You can kinda think of the `geometry` column containing the `.shp` part of a shapefile and the other columns being the stuff in the `.dbf` part of a shapefile. The GeoDataFrame mashes these two parts into one _object_. This clear link between the data and coordinates is very powerful and quite intuitive, IMHO. If you delete or select a row (or rows) in the GeoDataFrame using standard pandas slicing, the spatial part just comes along for the ride since it's another column. \n",
    "\n",
    "We did not talk much about the **Series** object in pandas; it is like a single column from a pandas DataFrame. The counterpart in GeoPandas is the **GeoSeries**. Whereas a Series object can contain any content that is legit for a DataFrame column, a GeoSeries is exclusively a `geometry` column. It is like a shapefile without the `.dbf` part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and manipulating spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in a shapefile is similar to how we read in a CSV in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_counties = gpd.read_file('spatial_data/cntbnd_jul11.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but now we get a GeoDataFrame instead of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fl_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the GeoDataFrame is built on top of pandas, we get lots of our familiar tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_counties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Open `cntbnd_jul11.shp` in ArcGIS or QGIS. Notice that the columns in the GeoDataFrame above match what is in the attribute table, with the exception of the `geometry` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the `shape` attribute below indicates that we have all 67 counties in the state of Florida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_counties.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might be good to take a peek at a map to confirm that we've got them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has some boilerplate plotting setup\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8,8  # change this line if you want to change the default map size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line may be a little slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-liner to get a basic map\n",
    "fl_counties.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stop for a second and absorb what just happened. We opened a shapefile with one line:\n",
    "```\n",
    "fl_counties = gpd.read_file('spatial_data/cntbnd_jul11.shp') \n",
    "```\n",
    "and then plotted it with one line:\n",
    "```\n",
    "fl_counties.plot()\n",
    "```\n",
    "Not only that, we have access to all the attributes in the DBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_counties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_counties.NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what's going with the `geometry` column?  Let's take a look at the first county in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fl_counties.geometry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So its type is a shapely `Polygon`. Again we see that geopandas relies heavily on its dependencies.  What is inside of a shapely `Polygon`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fl_counties.geometry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa!!! It contains all the X-Y coordinates needed to draw the polygon. Remember from introductory GIS that a polygon is represented by series points, and the GIS then \"connects the dots\" to form a polygon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we rerun the previous cell without the `print` statement. Geopandas has some nice defaults, eh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_counties.geometry[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cty_idx = 5\n",
    "print(fl_counties.NAME[cty_idx])\n",
    "fl_counties.geometry[cty_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a new object with just Leon County, the same way we would do with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon = fl_counties.loc[fl_counties.NAME=='LEON',:]\n",
    "leon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The new object is also a GeoDataFrame with the same 8 columns we had before, and the same methods and attributes; but only one row. \n",
    "\n",
    "Raise your hand if you thought the `leon` object was a GeoSeries. It is not; it is still a GeoDataFrame. Why? A GeoSeries is a single _column_ (just the `geometry` part); in contrast, the `leon` object is a single _row_ with multiple columns.\n",
    "\n",
    "(Don't worry, no one was looking if you got that question wrong.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the major roads for Florida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_roads = gpd.read_file('spatial_data/majrds_oct15.shp')\n",
    "fl_roads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_roads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_roads.plot()  # this is slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `geometry` column for the roads file. The county data frame contained shapely `Polygon` objects, what type do you think the roads will be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fl_roads.geometry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fl_roads.geometry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a pretty big file, which takes a long time to draw. Let's clip it to just Leon County. (It will take a couple of steps to do this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at two approaches to getting just the Leon County roads. First, we will find the intersection of the Leon County polygon and the Florida roads lines. (This is slow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_shp = leon.geometry.iloc[0]  # we are isolating just the Leon county polygon\n",
    "type(leon_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads1 = fl_roads.intersection(leon_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: Notice that the `intersection` method takes a shapely object NOT a geopandas object. This is important to remember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we'll find all the roads that `intersect` Leon County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_roads.intersects(leon_shp).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads2 = fl_roads.loc[fl_roads.intersects(leon_shp),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmmm. Something looks fishy here. The first plot looks pretty good, right? The second plot looks kinda like the roads in Leon County, but there is some extra stuff hanging around. What's happening? The difference lies in `intersection` vs. `intersects`.\n",
    "\n",
    "Recall that `intersection` took a lot longer to run than `intersects`? If you don't remember, rerun the two approaches. \n",
    "\n",
    "* `intersects` is a _question_: \"Does any part of this road lie in (i.e., intersects) Leon County?\" It returns a boolean (`True` or `False`) for each road.\n",
    "* `intersection` is an _action_: \"Use the Leon County polygon as a cookie cutter on the Florida roads.\" It returns geometries, i.e., line segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the story doesn't end there. Neither `leon_roads1` nor `leon_roads2` is perfect alone.  Let's see why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(leon_roads1.shape)\n",
    "print(fl_roads.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: `leon_roads1` is a GeoSeries of the same length as `fl_roads`. It essentially zeros out the roads that don't intersect the polygon; thus keeping just the intersection of the roads that do intersect the polygon. Two issues here:\n",
    "\n",
    "  1. A GeoSeries only contains geometries, not all the attributes.\n",
    "  2. We don't really need to keep all the records for zeroed out rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with `leon_roads2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(leon_roads2.shape)\n",
    "print(fl_roads.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: `leon_roads2` has the shapefile attributes we want and is the correct length. However, it has those extra bits of road that fall outside Leon County."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that you are sitting on the edge of your seat wondering... How will he resolve this? Will he resolve this? Will this be a quiz question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_roads_temp = fl_roads.copy()\n",
    "fl_roads_temp.geometry = fl_roads_temp.intersection(leon_shp).geometry\n",
    "leon_roads = fl_roads_temp.loc[fl_roads_temp.intersects(leon_shp),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking above...\n",
    "1. Make a copy of the state roads object.\n",
    "2. Clip the state roads to Leon County, but only save the geometries. Recall that the problem here is that we have a lot of rows with zeroed out geometries.\n",
    "3. Select just those roads that fall within Leon County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: The process of selecting the Leon County roads only takes three lines of python code. It is simple, but not as intuitive as we've come to expect from python. This was my best attempt for solving the problem. Can you identify a simpler (or more intuitive) way of getting this Leon County roads GeoDataFrame?  If you've got another approach, post it to the discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring it all together in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = leon.plot(color='green')\n",
    "leon_roads.plot(ax=ax, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did that plot work? When you want to plot two things on top of each other:\n",
    "- Plot the first layer as before, but now assign it to a variable\n",
    "- Plot the second layer as before, but now pass the first layer to the `ax` argument in the second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's plot some points on our map. We will open a national Twitter dataset provided by http://www.followthehashtag.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets_raw = pd.read_csv('spatial_data/dashboard_x_usa_x_filter_nativeretweets.csv',\n",
    "                         encoding = \"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a plain CSV file, which we opened as a regular pandas dataframe. We now need to convert to a geodataframe. The geogataframe needs shapely objects.  You've already seen polygons and lines, now it's time for points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_raw['xy'] = list(zip(tweets_raw.Longitude, tweets_raw.Latitude))\n",
    "tweets_raw['geometry'] = tweets_raw.xy.apply(shapely.geometry.Point)\n",
    "tweets = gpd.GeoDataFrame(tweets_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack the cell above.\n",
    "\n",
    "1. We \"zip\" the two columns together. This takes the content from the two columns and makes a tuple out of them. You can verify this with `tweets_raw.xy.head()`.\n",
    "2. The `apply` method is a really useful tool for a dataframe. It essentially says, \"apply this action to each row in the dataframe.\" In this case we are saying, \"make each element in the `tweets.xy` column a shapely `Point` object.\"\n",
    "3. Now that we have all the parts, we can convert the `tweets` dataframe into a geodataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our tweets. Since there are over 200,000 tweets, we want to use some alpha and make each point small. This is a little slow to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.plot(alpha=0.1, markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Action__: Play around with the marker size and alpha to see how it affects the information being communicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: I'm sure you noticed that there will be a problem placing these points on our Leon County map from earlier.  Hint: check out the scales on the above map and the ones earlier. Okay, since it's easy to do, let's just see what happens if we work with the data as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = leon.plot(color='green')\n",
    "tweets.plot(ax=ax, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [CRS](https://en.wikipedia.org/wiki/Spatial_reference_system) for our roads and counties were read in from the shapefile by geopandas. And these were transferred down the line as we sliced and diced the GeoDataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon_roads.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that earlier we learned that the `geometry` column contains the content from the `.shp` part of a shapefile and that the other columns contain the content from the `.dbf` part? Now we have learned that the `crs` attribute contains the information from the `.prj` part of a shapefile.\n",
    "\n",
    "In this case we are using `epsg:3087`, which is [Florida GDL Albers](http://spatialreference.org/ref/epsg/nad83harn-florida-gdl-albers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built the twitter GeoDataFrame from a CSV, so CRS info was not automatically populated. This is a really important concept to understand. A CSV file does not have any information on the projection of the data, but a shapefile does. \n",
    "\n",
    "Seriously, stop for a moment and think about this; it is a surprisingly difficult concept to absorb, but very important that you understand this. \n",
    "\n",
    "When pandas reads in the twitter data, it sees the `Longitude` and `Latitude` columns as any other columns containing floats. It has no way of knowing these are special. Guess what, ArcGIS doesn't know either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas needs to know the current CRS in order to convert to another CRS. We know that we have latitude and longitude from Twitter, so we can just populate the current CRS directly. Here is a [nice summary of using CRS in R](https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf), but as you can see below it is largely the same in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.crs = {'init': 'epsg:4326'}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual conversion is in the next cell. We'll just steal the CRS from the GeoDataFrame we want to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_crs(crs=leon_roads.crs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why was that last cell kind of slow? It was doing the math on every point to convert from one projection to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our tweets. Notice that they are in the correct projection now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.plot(alpha=0.1, markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to select just the Tweets in Leon County. Recall that we did this earlier to select roads in Leon County. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_leon = tweets.loc[tweets.intersects(leon_shp),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a real GIS question (finally!). Why is isolating the points in Leon County so much easier than isolating the roads in Leon County?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = leon.plot(color='green')\n",
    "tweets_leon.plot(ax=ax, color='blue', alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = leon.plot(color='green')\n",
    "leon_roads.plot(ax=ax, color='red', linewidth=0.5)\n",
    "tweets_leon.plot(ax=ax, color='blue', alpha=0.5)\n",
    "ax.set_xlim(360000,390000)\n",
    "ax.set_ylim(705000,730000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the above cell, if we want to fine tune the plot we need to use matplotlib syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of your work can then be written out to the hard drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_leon.drop('xy', 1, inplace=True)\n",
    "tweets_leon.to_file('spatial_data/tweets_leon.shp')\n",
    "leon_roads.to_file('spatial_data/leon_roads.shp')\n",
    "leon.to_file('spatial_data/leon_county.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of other fun things you can do with geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsu_tweets = tweets[tweets['Tweet content'].str.contains('fsu ', case=False)]\n",
    "for i in fsu_tweets['Tweet content']:\n",
    "    print(i)\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like all things related to pandas, you can string together crazy one-liners..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets['Tweet content'].str.contains('fsu ', case=False)].buffer(100000).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Spatial Analysis Library (PySAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">PySAL is an open source cross-platform library of spatial analysis functions written in Python. It is intended to support the development of high level applications for spatial analysis. First and foremost, PySAL is a library in the fullest sense of the word. Developers looking for a suite of spatial analytical methods that they can incorporate into application development should feel at home using PySAL. Spatial analysts who may be carrying out research projects requiring customized scripting, extensive simulation analysis, or those seeking to advance the state of the art in spatial analysis should also find PySAL to be a useful foundation for their work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples below are based on Jupyter Notebooks by Dani Arribas-Bel and Serge Rey, which can be found at [github.com/pysal/notebooks](https://github.com/pysal/notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pysal came along with the geopandas installation. If it did not and the cell below does not work correctly, run `conda install pysal` inside your newly created `gis2019` environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pysal.lib as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leon County Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at demographic data on census tracts in Leon County. A census tract is a statistical geography used for aggregating data collected by the US Census Bureau; these polygons tend to have approximately 4,000 people, and are often referred to as \"neighborhoods.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by opening the shapefile using the pysal reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shp = ps.io.open('spatial_data/leon_tracts.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various geometric information is immediately available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp.bbox  # bounding box of the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the individual observations by converting them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys = list(shp)\n",
    "print(\"number of tracts in Leon County:\", len(polys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract0 = polys[0]\n",
    "print(tract0)\n",
    "print(tract0.area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that pysal has its own polygon type whereas geopandas uses the shapely polygon type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract0.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tract0.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pysal, the `.shp` file is handled separately from the `.dbf` file. While the former contains the geometric information, the latter contains the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf = ps.io.open('spatial_data/leon_tracts.dbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We opened the `.shp` and `.dbf` files using the same `ps.io.open()` function. Pysal uses the file extension to determine how to open the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the `shp` object above, you can also inspect the `dbf` object. The following cell shows the column headers from the attribute table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf.header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who like databases, you can see the database specifications for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf.field_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see what is happening in any particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dbf.by_col('ALAND'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `by_col` method returns a list. Sometimes it's better to get a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf.by_col_array(['ALAND'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple columns can be extracted at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf.by_col_array(['ALAND', 'AWATER']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in some demographic data. It is typical that demographic data is acquired separately from the geometric information; which means they need to be merged after downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv = pd.read_csv('spatial_data/leon_tract_ests.csv')\n",
    "csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's swap out the cryptic names for something more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.columns = ['GEOID', 'population', \n",
    "               'pov_base', 'below_pov',\n",
    "               'edu_base', 'bach_higher',\n",
    "               'emp_base', 'unemp',\n",
    "               'households', 'sing_parent_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to be sure that the demographic data and the geometric data are in the same order. The `.dbf` file associated with the `.shp` file has `GEOID` column as does the `.csv` file, however the `.csv` version is prepended with a \"g\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.index = [i[1:] for i in csv.GEOID]\n",
    "target_index_order = dbf.by_col['GEOID']\n",
    "csv = csv.reindex(target_index_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf.by_col['GEOID'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: The dbf and csv data are now in the same order. We test this in the following cell. If you don't understand what is happing in the next cell, copy and paste the contents to a new cell and deconstruct it. Hmmmm... deconstructing a complex one-liner might make for a good quiz question. There are a few in this Notebook. You should practice how to do this and how to interpret the various parts.  Can you explain each part in the cell below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dbf.by_col_array(['GEOID']).flatten() == csv.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of much spatial analysis is the spatial weights matrix ($W$). The $W$ in an $n \\times n$ matrix that defines the relationship between all observations on the map. In the case of Leon County the matrix will be $68 \\times 68$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common weights structure is queen contiguity. This can be built directly from the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ps.weights.Queen.from_shapefile('spatial_data/leon_tracts.shp', idVariable='GEOID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `w` object has a lot of attributes and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.n  # number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `neighbors` attribute is a dictionary, where the key is the ID of interest and the value is a list of its neighbors' IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The weights matrix is stored in what is known as a [sparse](https://en.wikipedia.org/wiki/Sparse_matrix) format. Sparse data structures (of which there are many) only store the non-zero elements of the matrix. Technically there are 68*68 (4,624) elements in this matrix but we only need to store 406 of them since the rest are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of neighbors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.mean_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of neighbor relationship can be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w_hist_data = np.array(w.histogram)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.bar(w_hist_data[:,0], w_hist_data[:,1], align='center', width=1)\n",
    "ax.set_xlabel('number of neighbors')\n",
    "ax.set_ylabel('number of tracts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Looking at this histogram, you can see for example that there are three census tracts with nine neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `weights` attribute is the same structure as `neighbors` except that the value is a list of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Since this is a queen contiguity matrix, all the non-zero weights are one. Pysal also offers rook, bishop and distance weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights can be row-standardized so that the total weight for any observation sums to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.transform = 'R'\n",
    "w.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Look at the output above and notice that if you sum the weights for any observation, the total is one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance based weights are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist = ps.weights.Kernel.from_shapefile('spatial_data/leon_tracts.shp', idVariable='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist.mean_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist.weights  # this produces a lot of output!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Spatial Autocorrelation\n",
    "\n",
    "Most spatial data are spatially autocorrelated:\n",
    "\n",
    "First law of geography (W. Tobler):\n",
    "\n",
    "> Everything is related to everything else, but near things are more related than distant things. \n",
    "\n",
    "Another take on this (M. Goodchild):\n",
    "> Only Hell is spatially random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure spatial autocorrelation with the Moran's I. Let's see if we live in hell, i.e., identify if Leon County demographics are random or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysal.explore as pse\n",
    "pov_rate = csv.below_pov/(csv.pov_base*1.0)\n",
    "m_pov = pse.esda.Moran(pov_rate, w)\n",
    "m_pov.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Positive values of Moran's I indicate positive spatial autocorrelation (i.e., observations tend to be near observations that are similar to themselves), negative values indicate negative spatial autocorrelation (i.e., observations tend to be near observations that are different from themselves) and values near zero indicate a random pattern. The maximum and minimum values for Moran's I vary from dataset to dataset, but the possible values tend to range from about -1 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pop = pse.esda.Moran(csv.population, w)\n",
    "m_pop.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Let's compare these two results. We got a relatively high value for the poverty rate, indicating that poorer neighborhoods tend to be near one another and wealthier ones tend to be near one another. In contrast, the Moran's I value is close to zero for the population variable, seeming to indicate that there is no (or very little) spatial autocorrelation in the number of people in a census tract.  Does this mean that we are [living in hell](https://youtu.be/ydqkBG22Tk8) as Goodchild hinted? Recall that census tracts are designed to have approximately 4,000 people each so it's not surprising that there is no spatial pattern to these values; in contrast, poverty is the result of myriad societal processes manifest in Tobler's first law of geography."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the statistical significance of a Moran's I value. There are a number of ways to compute the significance of Moran's I; we'll consider the p-value based on simulations of Moran's I. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_pov.p_sim)\n",
    "print(m_pop.p_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Typical thresholds for identifying if a value is statistically significant are p-values of 0.01, 0.05 and 0.10. The results above indicate that the Moran's I for poverty rate is highly significant (its p-value is far below 0.01). The p-value for population on the other hand is above even the generous threshold of 0.10, indicating that even though the Moran's I is positive (0.051) it is not statistically different from zero (recall that zero indicates spatial randomness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a feel for the Moran's I results by looking at a scatter plot of the value of interest (in our case poverty rate or population) against the spatial lag of the variable (the average of the value in its neighboring census tracts). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "w_pov_rate = ps.weights.lag_spatial(w, pov_rate)\n",
    "#plt.figure(figsize=(5,5))\n",
    "ax[0].scatter(pov_rate, w_pov_rate, marker='.', s=20, alpha=1, color='k')\n",
    "ax[0].set_xlim(0,1)\n",
    "ax[0].set_ylim(0,1)\n",
    "ax[0].set_aspect('equal')\n",
    "ax[0].set_title(\"Poverty Rate\")\n",
    "w_population = ps.weights.lag_spatial(w, csv.population)\n",
    "ax[1].scatter(csv.population, w_population, marker='.', s=20, alpha=1, color='k')\n",
    "ax[1].set_xlim(0,10000)\n",
    "ax[1].set_ylim(0,10000)\n",
    "ax[1].set_aspect('equal')\n",
    "ax[1].set_title(\"Population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: There is a clear positive trend between the poverty rate and its spatial lag (indicating positive spatial autocorrelation), but for population the plot does not show much pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global Moran's I can identify if there the is an overall spatial pattern to the data. Local measures of spatial autocorrelation show if certain parts of the map exhibit spatial patterns in the data. In this case, you get a spatial autocorrelation value for each observation, instead of one for the entire map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mloc_pov = pse.esda.Moran_Local(pov_rate.values, w)\n",
    "mloc_pov.Is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also get a p-value for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mloc_pov.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pysal has some basic plotting functionality, which is useful for visualizing the Local Moran's I. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.viz.splot.esda import lisa_cluster\n",
    "leontracts = gpd.read_file('spatial_data/leon_tracts.shp')\n",
    "lisa_cluster(mloc_pov, leontracts, legend_kwds={'loc': 'upper left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The map shows tracts in red when they contain a relatively high poverty rate and are surrounded by other high tracts.  Blue tracts are relatively low poverty tracts, surrounded by other low poverty tracts. Does this map follow your intuition about the distribution of poverty in Leon County?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This was a brief introduction to two python packages focused on spatial data; there are a lot more.  I'm looking forward to seeing your presentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a) Open any shapefile you have on your computer using geopandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b) Plot the geodataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2a) Open the Leon County census tracts shapefile using geopandas (you used this in the pysal example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b) A geodataframe has a `centroids` attribute, which contains the geographic center of each each polygon. Create a new geodataseries or geodataframe containing the centroids and make one plot with the census tract polygons and census tract centroids."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
